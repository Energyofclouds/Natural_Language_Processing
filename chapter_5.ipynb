{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlao0mTz+UNlp3AjQRL4Vh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mj5v_39G9fFl"},"outputs":[],"source":["class RNN:\n","    def __init__(self, Wx, Wh, b):\n","        self.params = [Wx, Wh, b]\n","        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n","        self.cache = None\n","\n","    def forward(self, x, h_prev):\n","        Wx, Wh, b = self.params\n","        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n","        h_next = np.tanh(t)\n","\n","        self.cache = (x, h_prev, h_next)\n","        return h_next\n","\n","    def backward(self, dh_next):\n","        Wx, Wh, b = self.params\n","        x, h_prev, h_next = self.cache\n","\n","        dt = df_next * (1 - h_next ** 2)\n","        db = np.sum(dt, axis = 0)\n","        dWh = np.matmul(h_prev.T, dt)\n","        dh_prev = np.matmul(ddt, Wh.T)\n","        dWx = np.matmul(x.T, dt)\n","        dx = np.matmul(dt, Wx.T)\n","\n","        self.grads[0][...] = dWx\n","        self.grads[1][...] = dWh\n","        self.grads[2][...] = db\n","\n","        return dx, dh_prev"]}]}